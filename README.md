
ğŸš€ Rayâ€“vLLM ê¸°ë°˜ ë¶„ì‚° ì¶”ë¡  í”„ë ˆì„ì›Œí¬ 

ğŸš€ Distributed Inference Framework with Ray & vLLM for RAG-based LLM Serving


ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”
------------------------------------------------------------
ë³¸ í”„ë¡œì íŠ¸ëŠ” Ray ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° ìì› ìŠ¤ì¼€ì¤„ë§ê³¼
vLLMì˜ Paged Attention ê¸°ë°˜ KV ìºì‹œ ìµœì í™”ë¥¼ ê²°í•©í•˜ì—¬,

âœ… ëŒ€ê·œëª¨ LLM + RAG ì„œë¹„ìŠ¤ì˜
âœ… ì§€ì—°ì‹œê°„(TTFT, Latency) ê°ì†Œ
âœ… ì²˜ë¦¬ëŸ‰(TPS) ê·¹ëŒ€í™”

ë¥¼ ëª©ì ìœ¼ë¡œ í•œë‹¤.


ğŸ“Œ ë¹„êµ í‰ê°€ ëŒ€ìƒ ë¶„ì‚° êµ¬ì¡° (4ê°€ì§€)
------------------------------------------------------------
â‘  Single Node (Baseline)
â‘¡ Ray Actor Cluster (RAC)
â‘¢ Ray Serve Cluster (RSC)
â‘£ Ray + vLLM Cluster (RVC)

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ë…¼ë¬¸ì˜ ì‹¤í—˜ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤.

ğŸ“„ Performance Analysis of a Rayâ€“vLLM Based Distributed System for Efficient LLM Inference  
ğŸ› USTâ€“ETRI, 2025



ğŸ“‘ TABLE OF CONTENTS
============================================================
1. ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
2. êµ¬ì„± ìš”ì†Œ
3. ì„±ëŠ¥ í‰ê°€ ì§€í‘œ (KPM)
4. ì‹¤í—˜ ì½”ë“œ êµ¬ì„±
5. ì‹¤í–‰ í™˜ê²½
6. ì‹¤í–‰ ë°©ë²•
7. vLLM íŠœë‹ ì˜µì…˜
8. ë¶„ì‚° êµ¬ì¡°ë³„ í•µì‹¬ ì°¨ì´
9. í•µì‹¬ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½
10. í”„ë¡œì íŠ¸ ëª©ì  ìš”ì•½
11. í–¥í›„ í™•ì¥
12. Citation



âœ… 1. ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
============================================================

[ User Query ]
        â†“
[ RAG Pipeline (FAISS + ko-sroberta) ]
        â†“
[ Prompt Expansion ]
        â†“
[ Distributed Inference ]
        â†“
[ LLM Output ]



âœ… 2. êµ¬ì„± ìš”ì†Œ
============================================================

ğŸ”¹ RAG               : FAISS + ko-sroberta-multitask  
ğŸ”¹ LLM               : Qwen2.5-3B, Qwen2.5-1.5B-Instruct  
ğŸ”¹ Distributed Runtime: Ray (Multi-node, Multi-GPU)  
ğŸ”¹ Inference Optimizer: vLLM (Paged Attention, Continuous Batching)



âœ… 3. ì„±ëŠ¥ í‰ê°€ ì§€í‘œ (KPM)
============================================================

+-----------------+----------------------------------+
| ì§€í‘œ            | ì„¤ëª…                             |
+-----------------+----------------------------------+
| TTFT            | Time To First Token              |
| Latency_avg     | ìš”ì²­ 1ê°œë‹¹ í‰ê·  ì²˜ë¦¬ ì§€ì—°        |
| Latency_total   | ë¼ìš´ë“œ ì „ì²´ ë²½ì‹œê³„ ì§€ì—°          |
| TPS             | ì´ˆë‹¹ ì²˜ë¦¬ í† í° ìˆ˜                |
+-----------------+----------------------------------+

â€» ëª¨ë“  ì‹¤í—˜ì€
âœ” ë™ì¼í•œ ì§ˆë¬¸
âœ” ë™ì¼í•œ RPS
âœ” ë™ì¼í•œ ëª¨ë¸
ì¡°ê±´ì—ì„œ ìˆ˜í–‰ëœë‹¤.



âœ… 4. ì‹¤í—˜ ì½”ë“œ êµ¬ì„±
============================================================

+----------------------------+----------------------------+
| íŒŒì¼ëª…                     | ì„¤ëª…                      |
+----------------------------+--------------------------+
| baseline.py                | ë‹¨ì¼ ë…¸ë“œ ë©€í‹°ìŠ¤ë ˆë“œ ê¸°ë°˜ ì¶”ë¡ |
| baseline_fetched.py        | Baseline ê°œì„ íŒ |
| baseline_quality_check.py  | Baseline ì¶”ë¡  ê²°ê³¼ í’ˆì§ˆ ê²€ì¦|
| RayCluster_fetched.py      | Ray Actor ê¸°ë°˜ ë¶„ì‚° ì¶”ë¡ |
| RayServe_fetched.py        | Ray Serve ê¸°ë°˜ ì„œë¹™ êµ¬ì¡°|
| RayVllm_fetched.py         | Ray + vLLM í†µí•© ë¶„ì‚° ì¶”ë¡ |
+----------------------------+---------------------------+



âœ… 5. ì‹¤í–‰ í™˜ê²½
============================================================

ğŸ”¹ [5.1] í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
------------------------------------------------------------
pip install torch transformers langchain faiss-cpu ray vllm


ğŸ”¹ [5.2] ê³µí†µ í™˜ê²½ ë³€ìˆ˜ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
------------------------------------------------------------
export HF_HOME=/mnt/shared/hf-home  
export HF_HUB_OFFLINE=1  
export TRANSFORMERS_OFFLINE=1  
export HF_DATASETS_OFFLINE=1  


ğŸ”¹ [5.3] ë””ë ‰í† ë¦¬ êµ¬ì¡°
------------------------------------------------------------
/mnt/shared
 â”œâ”€â”€ faiss_index
 â””â”€â”€ models
     â”œâ”€â”€ ko-sroberta-multitask
     â”œâ”€â”€ qwen25_3b
     â””â”€â”€ qwen25_1_5b_instruct



âœ… 6. ì‹¤í–‰ ë°©ë²•
============================================================

ğŸ”¹ [6.1] Baseline (Single Node)
------------------------------------------------------------
python baseline.py

ë˜ëŠ” ê°œì„ íŒ:

python baseline_fetched.py


ğŸ”¹ [6.2] Ray Actor Cluster (RAC)
------------------------------------------------------------
ray start --head  
ray start --address=<HEAD_NODE_IP>:6379  
python RayCluster_fetched.py  


ğŸ”¹ [6.3] Ray Serve Cluster (RSC)
------------------------------------------------------------
ray start --head  
python RayServe_fetched.py  


ğŸ”¹ [6.4] Ray + vLLM Cluster (RVC)
------------------------------------------------------------
ray start --head  
python RayVllm_fetched.py  



âœ… 7. vLLM íŠœë‹ ì˜µì…˜
============================================================

export VLLM_MAX_MODEL_LEN=4096  
export VLLM_GPU_MEM_UTIL=0.69  
export VLLM_KV_CACHE_DTYPE=auto  
export VLLM_QUANT=awq  



âœ… 8. ë¶„ì‚° êµ¬ì¡°ë³„ í•µì‹¬ ì°¨ì´
============================================================

+-------------+--------------------------------------------+
| êµ¬ì¡°        | íŠ¹ì§•                                       |
+-------------+-------------------------------------------+
| Baseline    | ë‹¨ì¼ ë…¸ë“œ, Python Thread ê¸°ë°˜               |
| Ray Actor   | GPU 1ê°œë‹¹ Actor 1ê°œ, ëª…ì‹œì  ìŠ¤ì¼€ì¤„ë§         |
| Ray Serve   | HTTP ê¸°ë°˜ ì„œë¹™, Replica ë¶„ì‚°                |
| Ray + vLLM  | PagedAttention + ì—°ì† ë°°ì¹­/KVìºì‹œìµœì í™”     |
+-------------+--------------------------------------------+



âœ… 9. í•µì‹¬ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ (ë…¼ë¬¸ ê¸°ì¤€)
============================================================

+------------------+------------------+
| ì„±ëŠ¥ ì§€í‘œ        | ê°œì„ ë¥            |
+------------------+------------------+
| TTFT             | ğŸ”» 88.49% ê°ì†Œ   |
| í‰ê·  Latency     | ğŸ”» 72.99% ê°ì†Œ   |
| ì „ì²´ Latency     | ğŸ”» 70.97% ê°ì†Œ   |
| TPS              | ğŸ”º 171.18% ì¦ê°€  |
+------------------+------------------+

âœ” ê³ ë¶€í•˜(RPS â‰¥ 24) í™˜ê²½ì—ì„œ
âœ” ì—°ì† ë°°ì¹­ + KV ìºì‹œ í˜ì´ì§• íš¨ê³¼ ê·¹ëŒ€í™”
âœ” ë©”ëª¨ë¦¬ ë‹¨í¸í™” ê°ì†Œ ë° GPU ìœ íœ´ ì‹œê°„ ìµœì†Œí™”



âœ… 10. í”„ë¡œì íŠ¸ ëª©ì  ìš”ì•½
============================================================

RayëŠ” ğŸ”§ í´ëŸ¬ìŠ¤í„° ì „ì²´ ìì› ìŠ¤ì¼€ì¤„ë§ ë‹´ë‹¹  
vLLMì€ âš¡ ë…¸ë“œ ë‚´ë¶€ ì¶”ë¡  ê·¹í•œ ìµœì í™” ë‹´ë‹¹  

â¡ ì´ ë‘˜ì˜ ê²°í•©ì´
â¡ í˜„ì¬ êµ¬ì¡° ì¤‘ ê°€ì¥ ê°•ë ¥í•œ
â¡ LLM ë¶„ì‚° ì„œë¹™ í•´ë²•ì„ì„ ì‹¤ì¦í•œë‹¤.



âœ… 11. í–¥í›„ í™•ì¥
============================================================

- ğŸ“¦ Docker ê¸°ë°˜ Ray + vLLM ë°°í¬ ìŠ¤íƒ
- ğŸ”Œ gRPC ê¸°ë°˜ ì‹¤ì‹œê°„ ì„œë¹™ API
- ğŸ”€ Multi-LLM íŒŒì´í”„ë¼ì¸ ìë™ ë¶„ì‚° ìŠ¤ì¼€ì¤„ë§
- ğŸ§  NPU ê¸°ë°˜ vLLM ëŸ°íƒ€ì„ ì´ì‹



âœ… 12. Citation
============================================================

@article{kang2025rayvllm,
  title  = {Performance Analysis of a Rayâ€“vLLM Based Distributed System for Efficient LLM Inference},
  author = {Kang, Minsu and Kim, Young-Joo and Kim, Seon-Tae},
  journal= {UST-ETRI},
  year   = {2025}
}


